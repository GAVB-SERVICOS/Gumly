{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee8866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install /home/diego.fan/Documents/dev_work/mlutils/dist/mlutils-1.0.0-py3-none-any.whl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc210d1",
   "metadata": {},
   "source": [
    "## 1.0 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b1fc9a",
   "metadata": {},
   "source": [
    "The main objective of this function is to make possible to use two different methods for dimentionality reduction (PCA and SVD) with the same API.\n",
    "\n",
    "Dimensionality reduction can be used with two techniques:\n",
    "- PCA (Principal Components Analysis) technique, which is often used to reduce the dimensionality of large data sets, by transforming a large set of variables into a smaller one that still contains most of the information in the large set.\n",
    "\n",
    "- SVD (Singular-Value Decomposition), that is a matrix decomposition method for reducing a matrix to its constituent parts in order to make certain subsequent matrix calculations simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa66ad3",
   "metadata": {},
   "source": [
    "## 1.1 Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d54fad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dimencionality reduction\n",
    "from mlutils.dimensionality_reduction import dimensionality_reduction\n",
    "\n",
    "#Others\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c2622",
   "metadata": {},
   "source": [
    "## 1.2 Using SVD  with numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df3ff7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34073313,  0.10864144],\n",
       "       [ 0.47650997,  0.17692445],\n",
       "       [ 0.70110855,  0.31684481],\n",
       "       [-0.0675579 ,  0.44724498],\n",
       "       [-0.17133298,  0.52770822],\n",
       "       [-0.36244574,  0.61481713]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = np.array(\n",
    "        [\n",
    "            [-1, -1, 2, -2],\n",
    "            [-2, -1, 3, -1],\n",
    "            [-3, -2, 5, 1],\n",
    "            [1, 1, 6, 1],\n",
    "            [2, 1, 7, 1],\n",
    "            [3, 2, 8, 1],\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "df_out = dimensionality_reduction(df, decomposition_method= \"SVD\", k=2)\n",
    "df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755984de",
   "metadata": {},
   "source": [
    "## 1.3 Using SVD with pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "442cec59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.64193043, -0.36654798,  0.51793037],\n",
       "       [ 0.47058286, -0.52545329,  0.44931113],\n",
       "       [-0.29821038,  0.00440589,  0.19035315],\n",
       "       [-0.16807708,  0.62149482,  0.47605606],\n",
       "       [ 0.36011535, -0.09608586,  0.35896259],\n",
       "       [ 0.34585357,  0.44049256,  0.37168509]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_df(m, n):\n",
    "    df = pd.DataFrame(np.random.rand(m,n))\n",
    "    return df\n",
    "\n",
    "df = get_df(6, 5)\n",
    "df_out = dimensionality_reduction(df, decomposition_method=\"SVD\", k=3)\n",
    "df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009658c6",
   "metadata": {},
   "source": [
    "## 1.4 Using PCA with Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ffce65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.55416303, -2.01120392],\n",
       "       [-3.29181646, -0.37102401],\n",
       "       [-2.55517195,  2.67830462],\n",
       "       [ 1.76504972,  0.04940415],\n",
       "       [ 2.9974995 ,  0.00646722],\n",
       "       [ 4.63860223, -0.35194805]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = np.array(\n",
    "        [\n",
    "            [-1, -1, 2, -2],\n",
    "            [-2, -1, 3, -1],\n",
    "            [-3, -2, 5, 1],\n",
    "            [1, 1, 6, 1],\n",
    "            [2, 1, 7, 1],\n",
    "            [3, 2, 8, 1],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "df_out = dimensionality_reduction(df, decomposition_method=\"PCA\", k=2)\n",
    "df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9000823d",
   "metadata": {},
   "source": [
    "## 1.5 Using PCA with pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f715cdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.55416303, -2.01120392, -0.17043529],\n",
       "       [-3.29181646, -0.37102401,  0.15484655],\n",
       "       [-2.55517195,  2.67830462, -0.13828135],\n",
       "       [ 1.76504972,  0.04940415,  0.50760573],\n",
       "       [ 2.9974995 ,  0.00646722, -0.18007924],\n",
       "       [ 4.63860223, -0.35194805, -0.1736564 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out = dimensionality_reduction(df, decomposition_method=\"PCA\", k=3)\n",
    "df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110c7121",
   "metadata": {},
   "source": [
    "## 2.0 Conclusion and library advantages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3107e064",
   "metadata": {},
   "source": [
    "This implementation is an advantage for dimentionality reduction process during the development of ML models due to its possibility to use to different techniques (PCA and SVD) by only changing the decomposition_method parameter. It allows the data scientist to run several different tests for better results in terms of explained variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab6d425",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[PCA Skitlearn](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
    "\n",
    "\n",
    "\n",
    "[SVD Sciypy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
