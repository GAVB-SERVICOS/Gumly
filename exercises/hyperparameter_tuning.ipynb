{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36a112b3",
   "metadata": {},
   "source": [
    "## 1.0 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3330c2c6",
   "metadata": {},
   "source": [
    "The main objective of this feature is to implement the use of hyperparameter tuning process for the development of Machine Learning models. The tutorial consists of the use of iris and boston datasets from sklearn Datasets, where the Data Scientists can choose the parameters to be tested for the method that is a wrapper of optuna opimization framework.\n",
    "\n",
    "The params to be chosen are:\n",
    "- df: DataFrame pandas\n",
    "- target: target variable\n",
    "- parameters: Dict that contains all the threshold given for optimization testing\n",
    "- algorithm: Machine Learning algorithm used for fit the model (eg: RandomForestClassifier, RandomForestRegressor)\n",
    "- metric: Metric used for the evaluation of the tests (eg: accuracy_score, r2)\n",
    "- scoring_option: Maximize or minimize objectives\n",
    "-  n_trials: The of trials that the framework must perform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc43d17",
   "metadata": {},
   "source": [
    "## 1.1 Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf9e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from mlutils.hyperparameter_tuning import hyperparameter_tuning\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4bf44c",
   "metadata": {},
   "source": [
    "## 1.2 Gathering the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a783239d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for classification \n",
    "iris_data = datasets.load_iris()\n",
    "df_iris = pd.DataFrame(data=iris_data.data, columns=iris_data.feature_names)\n",
    "df_iris[\"target\"] = iris_data.target\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23855c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for regression\n",
    "boston_data = datasets.load_boston()\n",
    "df_boston = pd.DataFrame(boston_data.data, columns=boston_data.feature_names)\n",
    "df_boston[\"target\"] = boston_data.target\n",
    "df_boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d6ce0a",
   "metadata": {},
   "source": [
    "## 1.3 Running hyperparameter tuning for classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a509ed09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-26 22:40:14,227]\u001b[0m A new study created in memory with name: no-name-0170e4b5-3464-44bf-a423-9a296e51398a\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:15,282]\u001b[0m Trial 0 finished with value: 0.29333333333333333 and parameters: {'min_samples_leaf': 375, 'max_depth': 952, 'n_estimators': 735}. Best is trial 0 with value: 0.29333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:15,511]\u001b[0m Trial 1 finished with value: 0.29333333333333333 and parameters: {'min_samples_leaf': 599, 'max_depth': 166, 'n_estimators': 166}. Best is trial 0 with value: 0.29333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:16,359]\u001b[0m Trial 2 finished with value: 0.29333333333333333 and parameters: {'min_samples_leaf': 59, 'max_depth': 868, 'n_estimators': 606}. Best is trial 0 with value: 0.29333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:17,694]\u001b[0m Trial 3 finished with value: 0.29333333333333333 and parameters: {'min_samples_leaf': 709, 'max_depth': 32, 'n_estimators': 971}. Best is trial 0 with value: 0.29333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:17,977]\u001b[0m Trial 4 finished with value: 0.29333333333333333 and parameters: {'min_samples_leaf': 833, 'max_depth': 222, 'n_estimators': 191}. Best is trial 0 with value: 0.29333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:18,706]\u001b[0m Trial 5 finished with value: 0.29333333333333333 and parameters: {'min_samples_leaf': 184, 'max_depth': 312, 'n_estimators': 530}. Best is trial 0 with value: 0.29333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:19,574]\u001b[0m Trial 6 finished with value: 0.29333333333333333 and parameters: {'min_samples_leaf': 432, 'max_depth': 300, 'n_estimators': 617}. Best is trial 0 with value: 0.29333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:20,098]\u001b[0m Trial 7 finished with value: 0.29333333333333333 and parameters: {'min_samples_leaf': 140, 'max_depth': 300, 'n_estimators': 374}. Best is trial 0 with value: 0.29333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:20,388]\u001b[0m Trial 8 finished with value: 0.29333333333333333 and parameters: {'min_samples_leaf': 457, 'max_depth': 788, 'n_estimators': 209}. Best is trial 0 with value: 0.29333333333333333.\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:20,470]\u001b[0m Trial 9 finished with value: 0.29333333333333333 and parameters: {'min_samples_leaf': 515, 'max_depth': 597, 'n_estimators': 57}. Best is trial 0 with value: 0.29333333333333333.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'min_samples_leaf': 375, 'max_depth': 952, 'n_estimators': 735},\n",
       " 0.29333333333333333)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameter_tuning(\n",
    "        df=df_iris,\n",
    "        target=\"target\",\n",
    "        parameters=[\n",
    "        {\"name\": \"min_samples_leaf\", \"type\": \"Integer\", \"low\": 1, \"high\": 1000},\n",
    "        {\"name\": \"max_depth\", \"type\": \"Integer\", \"low\": 12, \"high\": 1000},\n",
    "        {\"name\": \"n_estimators\", \"type\": \"Integer\", \"low\": 12, \"high\": 1000}\n",
    "    ],\n",
    "        algorithm=RandomForestClassifier,\n",
    "        metric=accuracy_score,\n",
    "        scoring_option=\"maximize\",\n",
    "        n_trials=10,\n",
    "        n_splits= 2,\n",
    "        suffle = True,\n",
    "        random_state= 42,\n",
    "        metric_goal='True'\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8771b293",
   "metadata": {},
   "source": [
    "## 1.4 Running hyperparameter tuning for regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de5bf787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-26 22:40:20,481]\u001b[0m A new study created in memory with name: no-name-93a5ba1b-93da-4e6f-a195-136889889196\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:21,377]\u001b[0m Trial 0 finished with value: 0.6983031292517003 and parameters: {'min_samples_leaf': 375, 'max_depth': 952, 'n_estimators': 735}. Best is trial 0 with value: 0.6983031292517003.\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:21,595]\u001b[0m Trial 1 finished with value: 0.7019469879518074 and parameters: {'min_samples_leaf': 599, 'max_depth': 166, 'n_estimators': 166}. Best is trial 0 with value: 0.6983031292517003.\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:22,332]\u001b[0m Trial 2 finished with value: 0.6988843417675097 and parameters: {'min_samples_leaf': 59, 'max_depth': 868, 'n_estimators': 606}. Best is trial 0 with value: 0.6983031292517003.\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:23,513]\u001b[0m Trial 3 finished with value: 0.6999597207918522 and parameters: {'min_samples_leaf': 709, 'max_depth': 32, 'n_estimators': 971}. Best is trial 0 with value: 0.6983031292517003.\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:23,747]\u001b[0m Trial 4 finished with value: 0.6968898196625948 and parameters: {'min_samples_leaf': 833, 'max_depth': 222, 'n_estimators': 191}. Best is trial 4 with value: 0.6968898196625948.\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:24,413]\u001b[0m Trial 5 finished with value: 0.6991704821802935 and parameters: {'min_samples_leaf': 184, 'max_depth': 312, 'n_estimators': 530}. Best is trial 4 with value: 0.6968898196625948.\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:25,179]\u001b[0m Trial 6 finished with value: 0.6992682874122097 and parameters: {'min_samples_leaf': 432, 'max_depth': 300, 'n_estimators': 617}. Best is trial 4 with value: 0.6968898196625948.\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:25,632]\u001b[0m Trial 7 finished with value: 0.70201045751634 and parameters: {'min_samples_leaf': 140, 'max_depth': 300, 'n_estimators': 374}. Best is trial 4 with value: 0.6968898196625948.\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:25,888]\u001b[0m Trial 8 finished with value: 0.7010947368421053 and parameters: {'min_samples_leaf': 457, 'max_depth': 788, 'n_estimators': 209}. Best is trial 4 with value: 0.6968898196625948.\u001b[0m\n",
      "\u001b[32m[I 2022-01-26 22:40:25,970]\u001b[0m Trial 9 finished with value: 0.7056 and parameters: {'min_samples_leaf': 515, 'max_depth': 597, 'n_estimators': 57}. Best is trial 4 with value: 0.6968898196625948.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'min_samples_leaf': 833, 'max_depth': 222, 'n_estimators': 191},\n",
       " 0.6968898196625948)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameter_tuning(\n",
    "        df=df_iris,\n",
    "        target=\"target\",\n",
    "        parameters=[\n",
    "        {\"name\": \"min_samples_leaf\", \"type\": \"Integer\", \"low\": 1, \"high\": 1000},\n",
    "        {\"name\": \"max_depth\", \"type\": \"Integer\", \"low\": 12, \"high\": 1000},\n",
    "        {\"name\": \"n_estimators\", \"type\": \"Integer\", \"low\": 12, \"high\": 1000}\n",
    "    ],\n",
    "        algorithm=RandomForestRegressor,\n",
    "        metric=mean_absolute_error,\n",
    "        scoring_option=\"minimize\",\n",
    "        n_trials=10,\n",
    "        n_splits= 2,\n",
    "        suffle = True,\n",
    "        random_state= 42,\n",
    "        metric_goal='False',\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45212dcf",
   "metadata": {},
   "source": [
    "## 2.0 Conclusion and library advantages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a760222e",
   "metadata": {},
   "source": [
    "This implementation is an advantage for feature selection process during the development of ML models due to its standardization. Basically, you are able to run several different methods for feature select only specifying basic hyperparameters and the dataFrame to be used. This makes very to run a lot of tests in order to get best set of features for the train/test phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bfae33",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657de6c7",
   "metadata": {},
   "source": [
    "[cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)\n",
    "\n",
    "\n",
    "[KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html?highlight=kfold#sklearn.model_selection.KFold)\n",
    "\n",
    "\n",
    "[optuna](https://optuna.readthedocs.io/en/v0.19.0/)\n",
    "\n",
    "\n",
    "[RandomSampler](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.samplers.RandomSampler.html)\n",
    "\n",
    "\n",
    "[make_scorer](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
